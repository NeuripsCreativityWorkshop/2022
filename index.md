## Introduction

Machine co-creativity continues to grow and attract a wider audience to machine learning. Generative models, for example, have enabled new types of media creation across language, images, and music including recent advances such as IMAGEN, Flamingo, and DALL·E2. This one-day workshop will broadly explore topics in the applications of machine learning to creativity and design, which includes:

*State-of-the-art algorithms for the creation of new media*. Machine learning models achieving state-of-the-art in traditional media creation tasks (e.g., image, audio, or video synthesis) that are also being used by the artist community will be showcased.

*Artist accessibility of machine learning models*. Researchers building the next generation of machine learning models for media creation will be challenged in understanding the needs of artists. Human Computer interaction and User Experience communities and those using developing machine learning-based creative tools.

*The social and cultural impact of these new models*. Ethical implications, ranging from the use of biased datasets, replicating artistic work, and potential eroding trust in media content.

*Artistic applications*. Finally, we will hear from some of the artists who are adopting machine learning--including deep learning and reinforcement learning--as part of their own artistic process.  

We will aim to balance addressing the technical issues and challenges of applying the latest Machine Learning models and techniques to creativity and design with the philosophical and cultural issues that surround this area of research.

The goal of this workshop is to bring together researchers and artists interested in exploring the intersection of human creativity and machine learning. This workshop solicits viewpoints from artists and technology developers to look beyond technical issues to better understand the needs of artists and creators. 

## Invited Speakers

* Aaron Hertzmann
* Alexa Steinbrück
* Mohammad Norouzi
* Yanghua Jin
* Kanru Hua
* Anastasiia Raina
* Eunsu Kang

## Schedule

Some of the below sessions will occur on our Discord server and some will occur in our Zoom livestream. You will find links to access all sessions at our [NeurIPS workshop website](https://neurips.cc/virtual/2022/workshop/49965) (registered participants only).

| Time    | Event  |
|---------|--------|
| 09:15 | Welcome and Introduction<br/>*Zoom* |
| 09:30 | Poster Session 1<br/>*All Posters; Discord* |
| 10:30 | *Speaker Presentation by Aaron Hertzmann; Zoom* |
| 11:00 | *Speaker Presentation by Alexa Steinbrück; Zoom* |
| 11:30 | *Speaker Presentation by Mohammad Norouzi; Zoom* |
| 12:00 | *Speaker Presentation / Stable Diffusion; Zoom* |
| 12:30 | Q&A Panel Discussion 1<br/>*Aaron Hertzmann, Alexa Steinbrück, others; Moderated by Bokar N'Diaye. *Zoom + Rocketchat* |
| 13:00 | Art Show <br/>*Zoom* |
| 13:30 | Social 1<br/>*Discord* |
| 14:00 | *Paper Orals; Zoom* |
| 14:30 | *Artwork Spotlights; Zoom* |
| 15:00 | AI Performance<br/>*Discord* |
| 16:00 | Poster Session 2<br/>*All Posters; Discord* |
| 17:00 | *Speaker Presentation by Anastasiia Raina; Zoom* |
| 17:30 | *Speaker Presentation by Eunsu Kang; Zoom* |
| 18:00 | *Speaker Presentation by Yanghua Jin; Zoom* |
| 18:30 | *Speaker Presentation by Kanru Hua; Zoom* |
| 19:00 | Q&A Panel Discussion 2<br/>*Anastasiia Raina, Eunsu Kang, Yanghua Jin, Kanru Hua; Moderated by Yingtao Tian. Zoom + Rocketchat* |
| 19:30 | Art Show (rebroadcast) <br/>*TBD* |
| 20:00 | Closing remarks<br/>*Zoom* |
| 20:15 | Social 2<br/>*Discord* |
| 21:00 | End |

## Accepted Papers

| # | Title    | Authors  |
|----------|--------|
| 1 | [Instrument Separation of Symbolic Music by Explicitly Guided Diffusion Model](papers/ml4cd2022_paper01.pdf) | Sangjun Han, Hyeongrae Ihm, DaeHan Ahn, Woohyung Lim  |
| 2 | [Videogenic: Video Highlights via Photogenic Moments](papers/ml4cd2022_paper02.pdf) | David Chuan-En Lin, Fabian Caba, Joon-Young Lee, Oliver Wang, Nikolas Martelaro |
| 3 | [Co-writing screenplays and theatre scripts alongside language models using Dramatron](papers/ml4cd2022_paper03.pdf)| Piotr Mirowski, Kory  W. Mathewson, Jaylen Pittman, Richard EVANS |
| *4 | [High-Resolution Image Editing via Multi-Stage Blended Diffusion](papers/ml4cd2022_paper04.pdf) | Johannes Ackermann, Minjun Li |
| 5 | [Language Does More Than Describe: On The Lack Of Figurative Speech in Text-To-Image Models](papers/ml4cd2022_paper05.pdf) | Ricardo Kleinlein, Cristina Luna-Jiménez, Fernando Fernández-Martínez |
| 6 | [Intentional Dance Choreography with Semi-Supervised Recurrent VAEs](papers/ml4cd2022_paper06.pdf) | Mathilde Papillon, Mariel Pettee, Nina Miolane |
| 7 | [Visualizing Semantic Walks](papers/ml4cd2022_paper07.pdf) | Shumeet Baluja, David Marwood |
| 8 | [Personalizing Text-to-Image Generation via Aesthetic Gradients](papers/ml4cd2022_paper08.pdf) | Victor Gallego |
| 9 | [3DGEN: A GAN-based approach for generating novel 3D models from image data](papers/ml4cd2022_paper09.pdf) | Antoine Schnepf, Ugo Tanielian, Flavian Vasile |
| 10 | [CICADA: Interface for Concept Sketches Using CLIP](papers/ml4cd2022_paper10.pdf) | Tomas Lawton |
| 11 | [VideoMap: Video Editing in Latent Space](papers/ml4cd2022_paper11.pdf) |  David Chuan-En Lin, Fabian Caba, Joon-Young Lee, Oliver Wang, Nikolas Martelaro|
| 12 | [How do Musicians Experience Jamming with a Co-Creative “AI”?](papers/ml4cd2022_paper12.pdf) | Notto J. W. Thelle, Rebecca Fiebrink |
| *13 | [Botto: A Decentralized Autonomous Artist](pending) | Mario Klingeman, Simon Hudson, Zivvy Epstein |
| 14 | [Surreal VR Pong: LLM approach to Game Design](papers/ml4cd2022_paper14.pdf) | Jasmine A Roberts, Andrzej Banburski, Jaron Lanier |
| 15 | [Not All Artists Speak English: Generating images with DALL-E 2 from Portuguese](papers/ml4cd2022_paper15.pdf) | Gretchen Eggers |
| 16 | [Datasets That Are Not: Evolving Novelty Through Sparsity and Iterated Learning](papers/ml4cd2022_paper16.pdf) | Yusong Wu, Kyle Kastner, Tim Cooijmans, Cheng-Zhi Anna Huang, Aaron Courville |
| 17 | [Towards Real-Time Text2Video via CLIP-Guided, Pixel-Level Optimization](papers/ml4cd2022_paper17.pdf) | Peter Schaldenbrand, Zhixuan Liu, Jean Oh |
| 18 | [Sequence Modeling Motion-Captured Dance](papers/ml4cd2022_paper18.pdf) | Emily Napier, Gavia Gray, Sageev Oore |
| 19 | [A programmable interface for creative exploration](papers/ml4cd2022_paper19.pdf) | Gerard Serra, Oriol Domingo, Pol Baladas |

* Awaiting final version of paper

## Accepted Artworks

| # | Title    | Authors  |
|----------|--------|
| 1 | Armored Skin& Dark Seed | Jang, Yunyoung |
| 2 | Artificial intelligence breeding of underwater plants | HAKIMSHAFAEI, MILAD |
| 3 | Compressed ideographs -visualized- | Aoki, Seiya; Takaishi, Keito; Ishii, Asuka; Shibuya, Kazufumi; Matsuoka, Yuma; Kobayashi, Atsuya; Tokui, Nao |
| 4 | Song of Hairs | Tang, Song |
| 5 | Making Dance with Intention | Papillon, Mathilde; Pettee, Mariel; Miolane, Nina |
| 6 | Psychedelic Forms | Canet Sola, Mar; Guljajeva, Varvara |
| 7 | Dream Painter | Canet Sola, Mar; Guljajeva, Varvara |
| 8 | Little Science | Epstein, Vadim |
| 9 | Salvaging the beauty left behind | Takaishi, Keito; Ishii, Asuka; Shibuya, Kazufumi; Tokui, Nao |
| 10 | Hidden Clergy | Porres, Diego |
| 11 | Alt Nature | Ng, Zihou |
| 12 | Flowers for Frankenstein’s Monster | Schultz, Derrick |
| 13 | Interactive Afflatus | Naruse, Santa |
| 14 | Ducking Jorn | Fedeli, Filippo; Ainio, Anna Angelica |
| 15 | Autolume Acedia (2022) | Kraasch, Jonas F; Pasquier, Philippe |
| 16 | [a]life drawing | Estevez, David |
| 17 | Lockdown (music video) | Sun, Sophia H; Schedel, Margaret; Yuditskaya, Sofy; Rajan, Ria; Green-Mateu, Susan E |
| 18 | The Old Tune | Wiehe, Anton O |
| 19 | Old Sights, New Visions | Cole, Adam |
| 20 | we meet, we connect | rojas, sebastian; lab, hypereikon |
| 21 | The Quietest Remains | Thompson, Ryan |
| 22 | Reach Out | Růžička, Vít |
| 23 | The Faded Landscape | Cheng, Mingyong |
| 24 | Machine Reflections: A Self-Portrait Series | Szantho, Orsolya |
| 25 | Tasty Piano | Colas, Cédric |
| 26 | Incorporation: artwork | Teodorescu, Laetitia |

## Contact

If you have any questions, please contact us at *neuripscreativityworkshop@googlegroups.com*

Previous years:

* [2021 workshop](https://neuripscreativityworkshop.github.io/2021) (virtual)
* [2020 workshop](https://neurips2020creativity.github.io/) (virtual)
* [2019 workshop](http://neurips2019creativity.github.io/) (Vancouver, Canada)
* [2018 workshop](https://nips2018creativity.github.io/) (Montreal, Canada)
* [2017 workshop](https://nips2017creativity.github.io/) (Long Beach, CA, USA)

## How to attend

A registration ticket must be purchased on [neurips.cc](https://neurips.cc/). This will allow you to access our website on NeurIPS with links to the livestream, poster session and socials.

## Call for Submissions

We invite submissions in the form of papers and/or artwork. Deadline for submissions is ~~Monday 19 Sept~~ Extended! Monday Sept 26 (11:59pm, anywhere on earth)

### To Submit a Paper

We invite participants to submit 2-page papers in the [NeurIPS camera-ready format](https://neurips.cc/Conferences/2022/PaperInformation/StyleFiles) (with author names visible), to be submitted to [our CMT portal](https://cmt3.research.microsoft.com/ML4CD2022).

Topics may include (but are not limited to):

* Presentation of new machine learning techniques for generating art, music, or other creative outputs using, for instance, reinforcement learning, generative adversarial networks, novelty search and evaluation, etc
* Quantitative or qualitative evaluation of machine learning techniques for creative work and design
* Tools or techniques to improve usability or usefulness of machine learning for creative practitioners
* Descriptions, reflections, or case studies on the use of machine learning in the creation of a new art or design work

We encourage all authors to consider the ethical implications of their work. This can be discussed in a 1-paragraph section at the end of the paper and will not count towards the page limit.

In your submission, you may also indicate whether you would like to present a demo of your work during the workshop (if applicable).

Papers will be reviewed by committee members in a single-blind process, and accepted authors can present at the workshop in the form of a short talk, panel, and/or demo. At least one author of each accepted paper must register for and attend the workshop. Accepted papers will appear on the workshop website. Please note that we do not adhere to a formal peer review process and are normally unable to provide detailed feedback on individual submissions. We encourage submission of work that has been previously published, and work in progress on relevant topics of the workshop. This workshop will not have an official proceedings.

References and any supplementary materials provided do not count as part of the 2-page limit. However, it will be the reviewers’ discretion to read the supplementary materials.


### To Submit Artwork

We welcome submission of artwork that has been created using machine learning (autonomously or with humans). We invite art submissions in any medium, including but not limited to:

* Image
* Video
* Music
* Writing
* Sound
* Dance, Performance, Installation, Physical Object, Food, etc

This year we are asking for submissions to consist of:

* In a text file, include the title, year, artist(s), and description (up to 200 words). Name the text file like: project_name_00.txt.
* One 1080 x 1920 landscape image. Name this image like: project_name_01.png. Both PNG and JPG/JPEG formats are acceptable. This image could be a work of art itself, or a single cover slide to describe the project.
* Optional: Up to 3 additional 1080 x 1920 landscape images. Name these like: project_name_03.png, project_name_04.png, project_name_05.png.
* Optional: One 1080 x 1920 MP4 landscape video of up to 60 seconds showing the work in more detail. Name this like: project_name_03.mp4.

Place these in a single zip archive called project_name.zip. 

Submit this zip file through [our CMT portal](https://cmt3.research.microsoft.com/ML4CD2022).

The reason for this specific submission format is simply for standardization in the review / judging process of the art submissions. Do not worry too much about this. 

For accepted works, eventually some text and one (or more) images or video will be displayed in an online gallery. Please see [last year's gallery site](https://neuripscreativityworkshop.github.io/2021/#/gallery) for reference. Later on, for accepted works, we will allow another opportunity to edit and/or include links in the text description to alternate formats of the work that may be better suited for the artwork's presentation.

In addition, during the online workshop itself we will show a number of accepted art pieces as a slideshow (which is why we ask for the landscape format). We also may invite a few select creators of accepted artwork to participate in the form of a short talk, panel, and/or demo.

## Organisers

Samaneh Azadi<br>
Lia Coleman<br>
Yingtao Tian<br>
Tom White<br>
